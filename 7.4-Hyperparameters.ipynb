{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "extensive-present",
   "metadata": {},
   "source": [
    "---\n",
    "# Section 7.4: Hyperparameters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, LaTeXStrings\n",
    "using LinearAlgebra, Statistics, Random, Printf\n",
    "using Parameters: @with_kw\n",
    "\n",
    "using MLDataUtils\n",
    "using MLBase\n",
    "\n",
    "using Flux\n",
    "using Flux: params\n",
    "using Flux.Losses: mse\n",
    "using Flux.Data: DataLoader\n",
    "using Flux.Optimise\n",
    "using Flux.Losses: binarycrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Himmelblau function\n",
    "\n",
    "f(x) = (x[1]^2 + x[2] - 11)^2 + (x[1] + x[2]^2 - 7)^2\n",
    "f(x,y) = f([x,y])\n",
    "\n",
    "ax, bx = -6, 6\n",
    "ay, by = -6, 6\n",
    "\n",
    "xx = range(ax, bx, length=200)\n",
    "yy = range(ay, by, length=200)\n",
    "flevels = [0, 5, 20, 40, 60, 80, 100, 120, 150, 180, 300, 400, 600]\n",
    "\n",
    "plt1 = plot(xlabel=L\"x\", ylabel=L\"y\", aspect_ratio=:equal, colorbar=:none, size=(600,600),\n",
    "    xlims=(ax,bx), ylims=(ay,by), legend=:none)\n",
    "contour!(xx, yy, f, levels=flevels, color=1, contour_labels=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000\n",
    "\n",
    "X = 12*rand(Float32, 2, N) .- 6\n",
    "y = reshape([f(X[:,i]) for i=1:N],1,N)\n",
    "\n",
    "train_inds, test_inds = splitobs(N, at=0.8)\n",
    "\n",
    "X_train, X_test = X[:,train_inds], X[:,test_inds]\n",
    "y_train, y_test = y[:,train_inds], y[:,test_inds]\n",
    "size(X_train), size(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw mutable struct Args\n",
    "    optalg = ADAM\n",
    "    batchsize::Int = 80\n",
    "    lr::Float64 = NaN\n",
    "    epochs::Int = 1000\n",
    "end\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "function estfun(train_inds; kws...)\n",
    "    \n",
    "    X̄ = X[:, train_inds]\n",
    "    ȳ = y[:, train_inds]\n",
    "\n",
    "    args = Args(; kws...)\n",
    "    \n",
    "    Random.seed!(1234)\n",
    "    model = Chain(\n",
    "        Dense(2, 16, relu),\n",
    "        Dense(16, 16, relu),\n",
    "        Dense(16, 16, relu),\n",
    "        Dense(16, 8, relu),\n",
    "        Dense(8, 8, relu),\n",
    "        Dense(8, 8, relu),\n",
    "        Dense(8, 4, relu),\n",
    "        Dense(4, 4, relu),\n",
    "        Dense(4, 2, relu),\n",
    "        Dense(2, 1))\n",
    "\n",
    "    loss(x, y) = mse(model(x), y)\n",
    "    ps = params(model)\n",
    "    data = DataLoader((X̄, ȳ), batchsize=args.batchsize)\n",
    "    if isnan(args.lr)\n",
    "        opt = args.optalg()\n",
    "    else\n",
    "        opt = args.optalg(args.lr)\n",
    "    end\n",
    "\n",
    "    for epoch = 1:args.epochs\n",
    "        train!(loss, ps, data, opt)\n",
    "    end\n",
    "    \n",
    "    return model\n",
    "end    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "function evalfun(model, test_inds; kws...)\n",
    "        \n",
    "    loss(x, y) = mse(model(x), y)\n",
    "    \n",
    "    X̄ = X[:, test_inds]\n",
    "    ȳ = y[:, test_inds]\n",
    "    \n",
    "    score = loss(X̄, ȳ)\n",
    "    \n",
    "    return score\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-killer",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = estfun(train_inds; epochs=100)\n",
    "score = evalfun(model, test_inds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-shore",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Cross-validation\n",
    "\n",
    "[MLBase cross-validation documentation](https://mlbasejl.readthedocs.io/en/latest/crossval.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blank-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for optimization algorithm\n",
    "\n",
    "@printf(\"%14s %20s\\n\", \"algorithm\", \"score\")\n",
    "for optalg in [Descent, Momentum, Nesterov, ADAM]\n",
    "    scores = cross_validate(\n",
    "        inds -> estfun(inds; optalg=optalg, epochs=100),\n",
    "        evalfun,\n",
    "        N,\n",
    "        Kfold(N, 4))\n",
    "\n",
    "    m, s = mean_and_std(scores)\n",
    "    \n",
    "    score = @sprintf(\"%.1f ± %.1f\", m, s)\n",
    "    @printf(\"%14s %20s\\n\", string(optalg), score)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for batchsize\n",
    "\n",
    "@printf(\"%14s %20s\\n\", \"batchsize\", \"score\")\n",
    "for batchsize in [40, 80, 100]\n",
    "    scores = cross_validate(\n",
    "        inds -> estfun(inds; batchsize=batchsize, epochs=1000),\n",
    "        evalfun,\n",
    "        N,\n",
    "        Kfold(N, 4))\n",
    "\n",
    "    m, s = mean_and_std(scores)\n",
    "    \n",
    "    score = @sprintf(\"%.1f ± %.1f\", m, s)\n",
    "    @printf(\"%14d %20s\\n\", batchsize, score)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation for learning rate\n",
    "\n",
    "@printf(\"%14s %20s\\n\", \"learning rate\", \"score\")\n",
    "for lr in [1e-2, 1e-3, 1e-4]\n",
    "    scores = cross_validate(\n",
    "        inds -> estfun(inds; lr=lr, epochs=1000),\n",
    "        evalfun,\n",
    "        N,\n",
    "        Kfold(N, 4))\n",
    "\n",
    "    m, s = mean_and_std(scores)\n",
    "    \n",
    "    score = @sprintf(\"%.1f ± %.1f\", m, s)\n",
    "    @printf(\"%14.0e %20s\\n\", lr, score)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-storage",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = estfun(train_inds)\n",
    "score = evalfun(model, test_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-nebraska",
   "metadata": {},
   "outputs": [],
   "source": [
    "F(x,y) = model(Matrix([x y]'))[1]\n",
    "\n",
    "plot(xlabel=L\"x\", ylabel=L\"y\", aspect_ratio=:equal, colorbar=:none, size=(600,600),\n",
    "    xlims=(ax,bx), ylims=(ay,by))\n",
    "contour!(xx, yy, f, levels=flevels, color=1, contour_labels=true)\n",
    "contour!(xx, yy, F, levels=flevels, color=:black, contour_labels=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt1 = plot(xlabel=L\"x\", ylabel=L\"y\", aspect_ratio=:equal, colorbar=:none, size=(600,600),\n",
    "    xlims=(ax,bx), ylims=(ay,by), legend=:none)\n",
    "contour!(xx, yy, f, levels=flevels, color=1, contour_labels=true)\n",
    "\n",
    "plt2 = plot(xlabel=L\"x\", ylabel=L\"y\", aspect_ratio=:equal, colorbar=:none, size=(600,600),\n",
    "    xlims=(ax,bx), ylims=(ay,by))\n",
    "contour!(xx, yy, F, levels=flevels, color=:black, contour_labels=true)\n",
    "\n",
    "plot(plt1, plt2, layout=(1,2), size=(900,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-olive",
   "metadata": {},
   "source": [
    "---\n",
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "function estfun_batch(train_inds; kws...)\n",
    "    \n",
    "    X̄ = X[:, train_inds]\n",
    "    ȳ = y[:, train_inds]\n",
    "\n",
    "    args = Args(; kws...)\n",
    "    \n",
    "    Random.seed!(1234)\n",
    "    model = Chain(\n",
    "        Dense(2, 16, sigmoid),\n",
    "        BatchNorm(16),\n",
    "        Dense(16, 8, sigmoid),\n",
    "        BatchNorm(8),\n",
    "        Dense(8, 4, sigmoid),\n",
    "        BatchNorm(4),\n",
    "        Dense(4, 2, sigmoid),\n",
    "        BatchNorm(2),\n",
    "        Dense(2, 1))\n",
    "\n",
    "    loss(x, y) = mse(model(x), y)\n",
    "    ps = params(model)\n",
    "    data = DataLoader((X̄, ȳ), batchsize=args.batchsize)\n",
    "    if isnan(args.lr)\n",
    "        opt = args.optalg()\n",
    "    else\n",
    "        opt = args.optalg(args.lr)\n",
    "    end\n",
    "\n",
    "    for epoch = 1:args.epochs\n",
    "        train!(loss, ps, data, opt)\n",
    "    end\n",
    "    \n",
    "    return model\n",
    "end    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-protection",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = estfun_batch(train_inds)\n",
    "score = evalfun(model, test_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fallen-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8\n",
    "@show k\n",
    "@show model[k]\n",
    "layers = Flux.activations(model, X_train)\n",
    "C = cov(layers[k], dims=2)\n",
    "maxC = maximum(abs.(C))\n",
    "heatmap(C, c=:balance, clims=(-maxC, maxC), yflip=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 9\n",
    "@show model[k]\n",
    "psk = params(model[k])\n",
    "[psk[1] psk[2]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "F(x,y) = model(Matrix([x y]'))[1]\n",
    "\n",
    "plot(xlabel=L\"x\", ylabel=L\"y\", aspect_ratio=:equal, colorbar=:none, size=(600,600),\n",
    "    xlims=(ax,bx), ylims=(ay,by))\n",
    "contour!(xx, yy, f, levels=flevels, color=1, contour_labels=true)\n",
    "contour!(xx, yy, F, levels=flevels, color=:black, contour_labels=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-fifteen",
   "metadata": {},
   "source": [
    "---\n",
    "# Dropout\n",
    "\n",
    "[Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 60\n",
    "\n",
    "posinds = findall(y_train[:] .<= cutoff)\n",
    "neginds = findall(y_train[:] .> cutoff)\n",
    "\n",
    "length(posinds), length(neginds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-buyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xlabel=L\"x\", ylabel=L\"y\", aspect_ratio=:equal, size=(600,600),\n",
    "    xlims=(ax,bx), ylims=(ay,by))\n",
    "contourf!(xx, yy, (x,y) -> f(x,y) <= cutoff, c=:binary)\n",
    "Plots.scatter!(X_train[1,posinds], X_train[2,posinds], c=2, label=:none)\n",
    "Plots.scatter!(X_train[1,neginds], X_train[2,neginds], c=3, label=:none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = length(y_train)\n",
    "yb = 1f0*(y .<= cutoff)\n",
    "yb_train, yb_test = yb[:,1:N_train], yb[:,N_train+1:N]\n",
    "size(X_train), size(yb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(1234)\n",
    "\n",
    "model = Chain(\n",
    "    Dense(2, 16, relu),\n",
    "    Dense(16, 16, relu),\n",
    "    Dense(16, 8, relu),\n",
    "    Dropout(0.5),\n",
    "    Dense(8, 4, relu),\n",
    "    Dense(4, 2, relu),\n",
    "    Dense(2, 1, sigmoid))\n",
    "\n",
    "loss(x, y) = binarycrossentropy(model(x), y)\n",
    "accuracy(x,y) = 100*sum(abs.(round.(model(x)) .== y))/length(y)\n",
    "\n",
    "ps = params(model)\n",
    "\n",
    "F(x,y) = round(model([x,y])[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-footage",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader((X_train, yb_train), batchsize=400)\n",
    "\n",
    "opt = ADAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-destination",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Flux.trainmode!(model)\n",
    "\n",
    "@time begin\n",
    "    epochs = 2000\n",
    "    for epoch = 1:epochs\n",
    "        train!(loss, ps, data, opt)\n",
    "        if epoch%100==0\n",
    "            @show loss(X_train, yb_train)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "Flux.testmode!(model)\n",
    "@show accuracy(X_train, yb_train)\n",
    "@show accuracy(X_test, yb_test)\n",
    "\n",
    "plot(xlabel=L\"x\", ylabel=L\"y\", aspect_ratio=:equal, size=(600,600),\n",
    "    xlims=(ax,bx), ylims=(ay,by))\n",
    "contourf!(xx, yy, F, c=:binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "posinds = findall(y_test[:] .<= cutoff)\n",
    "neginds = findall(y_test[:] .> cutoff)\n",
    "\n",
    "plt1 = plot(aspect_ratio=:equal, size=(600,600), xlims=(ax,bx), ylims=(ay,by), legend=:none)\n",
    "contourf!(xx, yy, (x,y) -> f(x,y) <= cutoff, c=:binary)\n",
    "Plots.scatter!(X_test[1,posinds], X_test[2,posinds], c=2, label=:none)\n",
    "Plots.scatter!(X_test[1,neginds], X_test[2,neginds], c=3, label=:none)\n",
    "\n",
    "plt2 = plot(aspect_ratio=:equal, size=(600,600), xlims=(ax,bx), ylims=(ay,by), legend=:none)\n",
    "contourf!(xx, yy, F, c=:binary)\n",
    "Plots.scatter!(X_test[1,posinds], X_test[2,posinds], c=2, label=:none)\n",
    "Plots.scatter!(X_test[1,neginds], X_test[2,neginds], c=3, label=:none)\n",
    "    \n",
    "plot(plt1, plt2, layout=(1,2), size=(900,500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "original-relation",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
